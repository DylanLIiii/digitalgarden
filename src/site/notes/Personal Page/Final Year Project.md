---
{"dg-publish":true,"permalink":"/personal-page/final-year-project/"}
---



#private
<!--
- **Link to** [G2Net Detecting Continuous Gravitational Waves | Kaggle](https://www.kaggle.com/competitions/g2net-detecting-continuous-gravitational-waves/overview)
- **Tags** #æœºå™¨å­¦ä¹  #FYP
- **Reference** 
	- [GitHub - rwightman/pytorch-image-models](https://github.com/rwightman/pytorch-image-models#) -->

## Context

G2Net is a network of Gravitational Wave, Geophysics and Machine Learning scientists. At present only signals from merging black holes and neutron stars have been detected. There are potentially many continuous signals from neutron stars in our own galaxy. Among those remaining are continuous gravitational-wave signals. By helping G2Net in this challenge you'll enable scientists to improve their sensitivity. 

---

## Goals
To find continuous gravitational wave signals. 

Each data sample contains eitherÂ **real or simulated noise**and possiblyÂ a simulated continuous gravitational-wave signal (CW)Â . The task is toÂ identify**when a signal is presentÂ in the data (target=1).**

---

## Details
- Dataset 
	- Real Data
	- Data Generation 
- ML Method
	- Tabular Feature with TabNet 
	- Image Feature with ViT with CNN and EfficientNet (Pre-trained)
- challenges 
	- Noise 
	- Sample imbalance 
	- Human influence when label
---

### Dataset
#### Real Data
Real dataset is from two gravitational-wave interferometers provided by G2Net.
> This is a spectrogram contains a true gravitational-wave clearly with label 1 and 0.  
<!-- element style="width:100%"-->

![CleanShot2022-11-09at12.40.48@2x](https://tuchuang-1303124258.cos.ap-shanghai.myqcloud.com/uPic/CleanShot%202022-11-09%20at%2012.40.48@2x.png)
![CleanShot2022-11-09at12.40.10@2x](https://tuchuang-1303124258.cos.ap-shanghai.myqcloud.com/uPic/CleanShot%202022-11-09%20at%2012.40.10@2x.png)

Actually, numerous of images are full of noise and cannot identify by our eyes. 

#### Data Generation
> [!information] 
> There are less more than DS can utilize time-frequency data from two gravitational-wave interferometers (LIGO Hanford & LIGO Livingston). So we need more data generated by ourselves to enhance model infer. 
> Each sample is comprised of a set of Short-time Fourier Transforms (SFTs) and corresponding GPS time stamps for each interferometer.
> For image Classification, we use spectrogram. 
<!-- element style="width:90%"-->

<!--
- **Link to** 
	- [G2Net-[TF]-[ViT] | Kaggle](https://www.kaggle.com/code/lau01b/g2net-tf-vit/notebook#Convolutional-Neural-Network)
	- [G2Net EDA:Data size/span/time-gap | Kaggle](https://www.kaggle.com/code/konomuabe/g2net-eda-data-size-span-time-gap)
	- [Basic spectrogram image classification](https://www.kaggle.com/code/dylanhedded/basic-spectrogram-image-classification/edit) --> 

**Read Dataset**
This is unusual as we most of the time see data splits as 80:20 but in our case it is 1: 16 which indicates that the competition creators are encouraging participants to generate their own data.

![CleanShot2022-11-09at12.42.30@2x](https://tuchuang-1303124258.cos.ap-shanghai.myqcloud.com/uPic/CleanShot%202022-11-09%20at%2012.42.30@2x.png)

**For data generation** 

> This part is from *Riroriro* proposed on 2019 by Buskirk and Babiuc-Hamilton. 

We can capture a kind of signal (simulate). 

![CleanShot2022-11-09at12.52.52@2x](https://tuchuang-1303124258.cos.ap-shanghai.myqcloud.com/uPic/CleanShot%202022-11-09%20at%2012.52.52@2x.png)

Then we use Constant-Q to visualize 
![CleanShot2022-11-09at12.53.09@2x](https://tuchuang-1303124258.cos.ap-shanghai.myqcloud.com/uPic/CleanShot%202022-11-09%20at%2012.53.09@2x.png)


Standard CW signals can be parameterised in terms of two sets of parameters:
- the Doppler-modulation parametersÂ $\lambda$ 
- the amplitude parameters 

å¯¹äºç”±å¿«é€Ÿæ—‹è½¬å’Œå­¤ç«‹çš„ä¸­å­æ˜Ÿ (NS) å‘å°„çš„ CW, å¤šæ™®å‹’è°ƒåˆ¶å‚æ•°åŒ…æ‹¬é¢‘ç‡ F0 å’Œçº¿æ€§å¹³ç§»å‚æ•° F1, ä¸¤è€…å‡å–è‡ªå‚è€ƒæ—¶é—´ tref, ä»¥åŠä»¥èµ¤é“åæ ‡çš„èµ¤ç»è§’ Alpha å’Œèµ¤çº¬è§’ Delta ä¸ºå•ä½çš„å¤©ç©ºä½ç½®. å¦ä¸€æ–¹é¢, æŒ¯å¹…å‚æ•°åŒ…æ‹¬ CW ä¿¡å·çš„å¹³å‡æŒ¯å¹… h0, ä¿¡å·çš„åˆå§‹ç›¸ä½ phiã€åæŒ¯è§’ psi å’Œ (ä½™å¼¦) æºçš„å€¾æ–œè§’ cosi, è¿™ç»™æˆ‘ä»¬æä¾›äº† NS ç›¸å¯¹äºæ¢æµ‹å™¨çš„ç›¸å¯¹æ–¹å‘.

ä¸ºäº†äº§ç”Ÿå™ªå£°, éœ€è¦æŒ‡å®šä¸€ç»„æ£€æµ‹å™¨ï¼ˆæœ¬ä¾‹ä¸­ä¸º H1 æˆ– L1, æ ·æœ¬çš„æŒç»­æ—¶é—´å’Œå™ªå£°çš„æŒ¯å¹…è°±å¯†åº¦ sqrtSX.

ç”Ÿæˆçš„ Noise æ•°æ®è¢«ä¿å­˜ä¸ºå¦‚ä¸‹çš„çŸ­å‚…é‡Œå¶å˜æ¢ (Short Fourier Transforms (SFTs)çš„åˆ—è¡¨. 

![I3bCjw](https://tuchuang-1303124258.cos.ap-shanghai.myqcloud.com/uPic/I3bCjw.jpg)


## Method

### LGBM Features
<!--
- **Link to** 
	- [g2net : prepare features | Kaggle](https://www.kaggle.com/code/ahmedelfazouan/g2net-prepare-features) 
	- [g2net LGBM with smote and enn | Kaggle](https://www.kaggle.com/code/aspiring/g2net-lgbm-with-smote-and-enn)
	- [âœ… Explore the Training Data Files ğŸ“‚ | Kaggle](https://www.kaggle.com/code/ryanluoli2/explore-the-training-data-files) -->

Origin Data is HDF5 Files. **`hdf5`**Â stands forÂ **Hierarchical Data Format version 5**. Each hierarchy with metadata. 

![M5wWSy](https://tuchuang-1303124258.cos.ap-shanghai.myqcloud.com/uPic/M5wWSy.jpg)

- HDF5
	- groups 
		- groups 
			- Dataset 
**For our data, one sample**
- KeysViewHDF5 [groups]
	- HDF5 group (3 members )
		- KeysView['H1', 'L1', 'frequency_Hz']
		- H1
			- SFTs
			- Timestamps
		- L1
			- SFTs
			- Timestamps
		- Frequency_HZ
			- Values

For id `001121a05` 
![[CleanShot 2022-11-09 at 13.04.16@2x 1.png\|CleanShot 2022-11-09 at 13.04.16@2x 1.png]]

For H1_SFTs[0:2] 
```python
array([[-2.0178011e-24+1.7066067e-22j, -1.4645843e-23+9.6421383e-23j,
         1.3910385e-23-4.3923662e-23j, ...,
        -1.7177181e-23+1.2837293e-22j,  1.3892107e-22-8.2977672e-23j,
         7.2729580e-23+4.4559575e-23j],
       [-1.8711387e-22+1.0073502e-22j, -1.5109396e-22+9.3674566e-24j,
         5.0192982e-23-5.2098252e-23j, ...,
        -5.9722122e-23-1.0904593e-22j,  8.0738399e-23+1.6148876e-22j,
         1.4760140e-22+1.0795126e-22j]], dtype=complex64)

```

We just aggregate with randomness  to generate values in timestamps we need to create features. 

- 360 features with 1 target 
	- Contains SFTs information 
![[CleanShot 2022-11-09 at 13.07.32@2x.png\|CleanShot 2022-11-09 at 13.07.32@2x.png]]

Then use a **TabNet** to train our data then ensemble it to our main CV model. 

> [!information]
> TabNet is a Deep Neural Network for tabular data and was designed to learn in a similar way than decision tree based models, in order to have their benefits :Â **_interpretability_**Â andÂ **_sparse feature selection_**. TabNet usesÂ **_sequential attention to choose which features to reason from at each decision step_**, enabling interpretability and better learning (as the learning capacity is used for the most salient/important features). The feature selection is instancewise, so it can be different for each input.


### CV Features

The ViT with CNN model consists of multiple Transformer blocks.
- use MultiHeadAttention layer as a self-attention mechanism applied to the sequence of patches. 
- The Transformer blocks produce a [batch_size, num_patches, projection_dim] tensor, which is processed via a Dense head to produce the final output.



--- 

# Writing 

- Literature Review 
	- NetWork Part
		- LeNet 
		- AlexNet
		- InceptionNet
		- ResNet
		- MnasNet 
		- EfficientNet 
	- Tabular Learning Part 
- Methodology 
	- Data 


## Data 

To parameterize standard CW signals 
- Doppler-modulation parameters $\lambda$ : The fluctuation of signal frequent. 
	- the frequency â€™F0â€™ 
	- the linear spin-down parameter â€™F1â€™
	- 'F0' and 'F1' are taken at a reference time â€™trefâ€™, and the sky position in terms of the right ascension â€™Alphaâ€™ and declination â€™Deltaâ€™ angles  of equatorial coordinates for a CW emitted by a rapidly-spinning and isolated neutron star (NS).
-  the amplitude parameters $\mathcal{A}$: The overall amplitude of a CW based on the sourceâ€™s properties
	- The average amplitude of a CW signal 'h0'
	- initial phase 'phi'
	- polarization angle 'psi'
	- (the cosine of) the inclination angle of the  source â€™cosi' :  relative orientation of the NS in relation to the detector 
	- The am