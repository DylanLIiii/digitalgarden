---
{"dg-publish":true,"permalink":"/personal-page/customize-sklearn-model-selection/"}
---

#DataVisualisation 
- Infer
Â  Â  - [ğŸ‡®ğŸ‡¹ğŸï¸ TimeSeriesSplit: how to use it | Kaggle](https://www.kaggle.com/code/tomwarrens/timeseriessplit-how-to-use-it/notebook)

## GroupTimeSeriesSplit
[scikit-learn_plit.py at main Â· scikit-learn/scikit-learn](https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/model_selection/_split.py)
```python

class TimeSeriesSplit(_BaseKFold):

Â  Â  """Time Series cross-validator

Â  Â  Provides train/test indices to split time series data samples

Â  Â  that are observed at fixed time intervals, in train/test sets.

Â  Â  In each split, test indices must be higher than before, and thus shuffling

Â  Â  in cross validator is inappropriate.

Â  Â  This cross-validation object is a variation of :class:`KFold`.

Â  Â  In the kth split, it returns first k folds as train set and the

Â  Â  (k+1)th fold as test set.

Â  Â  Note that unlike standard cross-validation methods, successive

Â  Â  training sets are supersets of those that come before them.

Â  Â  Read more in the :ref:`User Guide <time_series_split>`.

Â  Â  .. versionadded:: 0.18

Â  Â  Parameters

Â  Â  ----------

Â  Â  n_splits : int, default=5

Â  Â  Â  Â  Number of splits. Must be at least 2.

Â  Â  Â  Â  .. versionchanged:: 0.22

Â  Â  Â  Â  Â  Â  ``n_splits`` default value changed from 3 to 5.

Â  Â  max_train_size : int, default=None

Â  Â  Â  Â  Maximum size for a single training set.

Â  Â  test_size : int, default=None

Â  Â  Â  Â  Used to limit the size of the test set. Defaults to

Â  Â  Â  Â  ``n_samples // (n_splits + 1)``, which is the maximum allowed value

Â  Â  Â  Â  with ``gap=0``.

Â  Â  Â  Â  .. versionadded:: 0.24

Â  Â  gap : int, default=0

Â  Â  Â  Â  Number of samples to exclude from the end of each train set before

Â  Â  Â  Â  the test set.

Â  Â  Â  Â  .. versionadded:: 0.24

Â  Â  Examples

Â  Â  --------

Â  Â  >>> import numpy as np

Â  Â  >>> from sklearn.model_selection import TimeSeriesSplit

Â  Â  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])

Â  Â  >>> y = np.array([1, 2, 3, 4, 5, 6])

Â  Â  >>> tscv = TimeSeriesSplit()

Â  Â  >>> print(tscv)

Â  Â  TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)

Â  Â  >>> for train_index, test_index in tscv.split(X):

Â  Â  ... Â  Â  print("TRAIN:", train_index, "TEST:", test_index)

Â  Â  ... Â  Â  X_train, X_test = X[train_index], X[test_index]

Â  Â  ... Â  Â  y_train, y_test = y[train_index], y[test_index]

Â  Â  TRAIN: [0] TEST: [1]

Â  Â  TRAIN: [0 1] TEST: [2]

Â  Â  TRAIN: [0 1 2] TEST: [3]

Â  Â  TRAIN: [0 1 2 3] TEST: [4]

Â  Â  TRAIN: [0 1 2 3 4] TEST: [5]

Â  Â  >>> # Fix test_size to 2 with 12 samples

Â  Â  >>> X = np.random.randn(12, 2)

Â  Â  >>> y = np.random.randint(0, 2, 12)

Â  Â  >>> tscv = TimeSeriesSplit(n_splits=3, test_size=2)

Â  Â  >>> for train_index, test_index in tscv.split(X):

Â  Â  ...Â  Â  print("TRAIN:", train_index, "TEST:", test_index)

Â  Â  ...Â  Â  X_train, X_test = X[train_index], X[test_index]

Â  Â  ...Â  Â  y_train, y_test = y[train_index], y[test_index]

Â  Â  TRAIN: [0 1 2 3 4 5] TEST: [6 7]

Â  Â  TRAIN: [0 1 2 3 4 5 6 7] TEST: [8 9]

Â  Â  TRAIN: [0 1 2 3 4 5 6 7 8 9] TEST: [10 11]

Â  Â  >>> # Add in a 2 period gap

Â  Â  >>> tscv = TimeSeriesSplit(n_splits=3, test_size=2, gap=2)

Â  Â  >>> for train_index, test_index in tscv.split(X):

Â  Â  ...Â  Â  print("TRAIN:", train_index, "TEST:", test_index)

Â  Â  ...Â  Â  X_train, X_test = X[train_index], X[test_index]

Â  Â  ...Â  Â  y_train, y_test = y[train_index], y[test_index]

Â  Â  TRAIN: [0 1 2 3] TEST: [6 7]

Â  Â  TRAIN: [0 1 2 3 4 5] TEST: [8 9]

Â  Â  TRAIN: [0 1 2 3 4 5 6 7] TEST: [10 11]

Â  Â  Notes

Â  Â  -----

Â  Â  The training set has size ``i * n_samples // (n_splits + 1)

Â  Â  + n_samples % (n_splits + 1)`` in the ``i`` th split,

Â  Â  with a test set of size ``n_samples//(n_splits + 1)`` by default,

Â  Â  where ``n_samples`` is the number of samples.

Â  Â  """

  

Â  Â  def __init__(self, n_splits=5, *, max_train_size=None, test_size=None, gap=0):

Â  Â  Â  Â  super().__init__(n_splits, shuffle=False, random_state=None)

Â  Â  Â  Â  self.max_train_size = max_train_size

Â  Â  Â  Â  self.test_size = test_size

Â  Â  Â  Â  self.gap = gap

  

Â  Â  def split(self, X, y=None, groups=None):

Â  Â  Â  Â  """Generate indices to split data into training and test set.

Â  Â  Â  Â  Parameters

Â  Â  Â  Â  ----------

Â  Â  Â  Â  X : array-like of shape (n_samples, n_features)

Â  Â  Â  Â  Â  Â  Training data, where `n_samples` is the number of samples

Â  Â  Â  Â  Â  Â  and `n_features` is the number of features.

Â  Â  Â  Â  y : array-like of shape (n_samples,)

Â  Â  Â  Â  Â  Â  Always ignored, exists for compatibility.

Â  Â  Â  Â  groups : array-like of shape (n_samples,)

Â  Â  Â  Â  Â  Â  Always ignored, exists for compatibility.

Â  Â  Â  Â  Yields

Â  Â  Â  Â  ------

Â  Â  Â  Â  train : ndarray

Â  Â  Â  Â  Â  Â  The training set indices for that split.

Â  Â  Â  Â  test : ndarray

Â  Â  Â  Â  Â  Â  The testing set indices for that split.

Â  Â  Â  Â  """

Â  Â  Â  Â  X, y, groups = indexable(X, y, groups) # å°† X, y, groups è½¬ä¸ºå¯ç´¢å¼•çš„å¯¹è±¡å¹¶è¿”å›

Â  Â  Â  Â  n_samples = _num_samples(X) # è¿”å› X ä¸­ Sample çš„æ•°é‡

Â  Â  Â  Â  n_splits = self.n_splitsÂ 

Â  Â  Â  Â  n_folds = n_splits + 1Â 

Â  Â  Â  Â  gap = self.gapÂ 

Â  Â  Â  Â  test_size = (

Â  Â  Â  Â  Â  Â  self.test_size if self.test_size is not None else n_samples // n_folds

Â  Â  Â  Â  )

  

Â  Â  Â  Â  # Make sure we have enough samples for the given split parameters

Â  Â  Â  Â  if n_folds > n_samples:

Â  Â  Â  Â  Â  Â  raise ValueError(

Â  Â  Â  Â  Â  Â  Â  Â  f"Cannot have number of folds={n_folds} greater"

Â  Â  Â  Â  Â  Â  Â  Â  f" than the number of samples={n_samples}."

Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  if n_samples - gap - (test_size * n_splits) <= 0:

Â  Â  Â  Â  Â  Â  raise ValueError(

Â  Â  Â  Â  Â  Â  Â  Â  f"Too many splits={n_splits} for number of samples"

Â  Â  Â  Â  Â  Â  Â  Â  f"={n_samples} with test_size={test_size} and gap={gap}."

Â  Â  Â  Â  Â  Â  )

  

Â  Â  Â  Â  indices = np.arange(n_samples)

Â  Â  Â  Â  test_starts = range(n_samples - n_splits * test_size, n_samples, test_size)

  

Â  Â  Â  Â  for test_start in test_starts:

Â  Â  Â  Â  Â  Â  train_end = test_start - gap

Â  Â  Â  Â  Â  Â  if self.max_train_size and self.max_train_size < train_end:

Â  Â  Â  Â  Â  Â  Â  Â  yield (

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  indices[train_end - self.max_train_size : train_end],

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  indices[test_start : test_start + test_size],

Â  Â  Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  yield (

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  indices[:train_end],

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  indices[test_start : test_start + test_size],

Â  Â  Â  Â  Â  Â  Â  Â  )

```